Jay Alammar. The illustrated transformer.

Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hin-
ton. 2016. Layer normalization.

Ilias Chalkidis. 2022. A nlp story from bag of words to
muppet show.

Andrew M Dai and Quoc V Le. 2015. Semi-supervised
sequence learning. Advances in neural information
processing systems.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. BERT: Pre-training of
Deep Bidirectional Transformers for Language Un-
derstanding. NAACL.

Apar Garg, Saiteja Adusumilli, Shanmukha Yenneti,
Tapas Badal, Deepak Garg, Vivek Pandey, Abhishek
Nigam, Yashu Kant Gupta, Gyan Mittal, and Rahul
Agarwal. 2021. News article summarization with
pretrained transformer.

John Haugeland. 1979. Understanding Natural Lan-
guage.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2016. Deep residual learning for image recogni-
tion.

Mahnaz Koupaee and William Yang Wang. 2018. Wiki-
how: A large scale text summarization dataset.

Derek Miller. 2019. Leveraging bert for extractive text
summarization on lectures.

Sinno Jialin Pan and Qiang Yang. 2010. A Survey on
Transfer Learning.

Alec Radford, Karthik Narasimhan, Tim Salimans, and
Ilya Sutskever. 2018. Improving language under-
standing with unsupervised learning. OpenAI.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J. Liu. 2020. Exploring the limits
of transfer learning with a unified text-to-text trans-
former.

Adam Roberts and Colin Raffel. 2020. Exploring trans-
fer learning with t5: the text-to-text transfer trans-
former.

Denis Rothman. 2021. Transformers for Natural Lan-
guage Processing, volume 1. Packt, Livery Place, 35
Livery Street, Birmingham B3 2PB, UK.

Ashutosh Vashisht. Bert for text summarization.
